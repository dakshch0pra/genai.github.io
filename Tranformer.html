<!DOCTYPE html>
<html>
    <head>
        <title>Transformers</title>
        <link rel="stylesheet" href="Transformer.css">
    </head>

    <body>
        <div class="color">
            <nav>
                <div class="brand"><a href="index.html">Generative AI</a></div>
                <ul>
                    <li class="home"><a href="index.html">Home</a></li>
                    <div class="links-container">
                        <li><a href="Introduction.html">Introduction</a></li>
                        <li><a href="History1.html">History</a></li>
                        <li><a href="working.html">Working</a></li>
                        <li><a href="application.html">Application</a></li>
                        <li><a href="ethics.html">Ethics</a></li>
                        <li><a href="future.html">Future</a></li>
                    </div>
                </ul>
            </nav>
        
            <div class="container">
                <div class="row">
                    <div class="column-1">
                        <h1>Transformer-Based Models</h1>
                        <p>At Right is the image of Ashish Vaswani and Jakob Uszkoreit, who created Transformer Based Models</p>
                    </div>
                    <div class="ai-ethic-image"><img src="transformer-creators-removebg-preview.png"></div>
                </div>
            </div>
        </div>

        <div class="ethic-container">
            <h2>Introduction</h2>
            <p>Transformer-based models have transformed the field of natural language processing (NLP) and artificial intelligence (AI). First introduced in 2017, these models are now essential for various AI applications, from language translation to generating human-like text. This guide aims to explain transformer-based models in a way that's easy 
            to understand, whether you're a college student from a non-technical background or just curious about AI.<br></p>
            <ul class="content">
                <li><h3>What is Transformer Model</h3>
                    <p>A transformer model is a type of deep learning model. Unlike earlier models that relied on processing data in 
                    sequences, transformers can handle data in parallel, making them faster and more efficient.</p>
                </li>

                <li><h3>Why Are They Important?</h3>
                    <p>Transformers are now widely used because they can perform many tasks more accurately and quickly than previous models. 
                    They are the backbone of popular AI tools like ChatGPT, which can generate text, answer questions, and summarize information.</p>
                </li>
            </ul>
            <br>
            <div class="encoder-decoder-photo">
            <img src="transformers-architecture.png">
            </div>
    
        
            <h2>How Transformer Models Work</h2>
            <ul class="content">
                <li><h3>Input Embeddings</h3>
                    <p>The model first converts words or pieces of text into numerical representations called embeddings. 
                    These embeddings capture the meaning and relationships between words.</p>
                </li>

                <li><h3>Positional Encoding</h3>
                    <p>Since transformers don't process data in sequence, they use positional encoding to keep track of the order of words. 
                    This involves assigning a unique number to each word to indicate its position in the sentence.</p>
                </li>

                <li><h3>Self-Attention</h3>
                    <p>This mechanism allows the model to weigh the importance of each word in relation to others. 
                    Imagine you're reading a sentence and trying to understand how each word connects to the restâ€”self-attention does this automatically.</p>
                </li>

                <li><h3>Multi-Head Attention</h3>
                    <p>Instead of using a single self-attention mechanism, transformers use multiple "heads" to 
                    capture different relationships between words. This helps the model understand complex patterns in the data.</p>
                </li>

                <li><h3>Feedforward Neural Networks</h3>
                    <p>After self-attention, the data is passed through feedforward networks, 
                    which apply additional transformations to capture more intricate relationships.</p>
                </li>

                <li><h3>Stacked Layers</h3>
                    <p>Transformers have multiple layers stacked on top of each other, each refining the data's representation. 
                    More layers mean the model can understand more abstract features.</p>
                </li>

                <li><h3>Output Layer</h3>
                    <p>For tasks like translation, a decoder module generates the output sequence based on the processed input.</p>
                </li>

                <li><h3>Training and Inference</h3>
                    <p>During training, the model learns to minimize errors by comparing its predictions to the actual results. 
                    Once trained, the model can make predictions on new data, like translating a sentence or answering a question.</p>
                </li>
            </ul>
            <br>
            <h2>Applications of Transformer Models</h2>
            <ul class="content">
                <li><h3>Language Generation</h3>
                    <p>Creating human-like text for chatbots, virtual assistants, and creative writing.</p>
                </li>

                <li><h3>Machine Translation</h3>
                    <p>Translating text from one language to another with high accuracy.</p>
                </li>

                <li><h3>Text Analysis</h3>
                    <p>Identifying the sentiment of a text, answering questions, classifying content, 
                    and recognizing named entities like people and places.</p>
                </li>

                <li><h3>Code Generation</h3>
                    <p>Helping programmers by suggesting code completions and summarizing code functionality.</p>
                </li>
            </ul>
            <br><br>

            <div class="board"><h4>Summary</h4>
                <div class="sum-board">Transformer-based models have revolutionized the field of AI and NLP, making it possible to perform tasks that were once thought impossible. Their ability to process data in parallel, understand complex relationships, and generate human-like text makes them powerful tools in the AI toolkit. However, they also come with challenges, such as high computational costs and data requirements. 
                Despite these drawbacks, the impact of transformer models on technology and everyday life is undeniable.<br> 
            </div>
            </div>
            <br><br>
            </div>
            <footer>
                <div class="footer-left">
                    <p>Made by Daksh Chopra<br>
                    B. TECH in CSE(AIML)<br>
                    Manipal University Jaipur</p>
                </div>
            </footer>
        </body>
            </html>
